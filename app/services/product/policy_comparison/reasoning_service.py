"""Service for generating natural language reasoning for policy comparisons."""

import json
from typing import List, Dict, Any, Optional
from app.core.unified_llm import UnifiedLLMClient
from app.core.config import settings
from app.schemas.workflows.policy_comparison import ComparisonChange
from app.utils.logging import get_logger
from app.utils.json_parser import parse_json_safely

LOGGER = get_logger(__name__)

class PolicyComparisonReasoningService:
    """Generates natural language explanations for policy differences using LLM."""

    def __init__(self):
        self.client = UnifiedLLMClient(
            provider=settings.llm_provider,
            api_key=settings.gemini_api_key if settings.llm_provider == "gemini" else settings.openrouter_api_key,
            model=settings.gemini_model if settings.llm_provider == "gemini" else settings.openrouter_model,
            base_url=settings.openrouter_api_url if settings.llm_provider == "openrouter" else None,
        )

    async def enrich_changes_with_reasoning(
        self, changes: List[ComparisonChange]
    ) -> List[ComparisonChange]:
        """Enriches each change with a reasoning string generated by LLM.
        
        To optimize, we batch changes by section and entity to reduce LLM calls.
        """
        if not changes:
            return []

        # Group changes to minimize LLM calls
        # We group by section_type for now. 
        # For large numbers of changes, we might want further sub-grouping.
        groups = {}
        for change in changes:
            if change.change_type == "no_change":
                continue
            
            section = change.section_type
            if section not in groups:
                groups[section] = []
            groups[section].append(change)

        enriched_changes = {id(c): c for c in changes}

        for section_type, section_changes in groups.items():
            try:
                # Prepare batch prompt
                batch_data = [
                    {
                        "id": id(c),
                        "field": c.field_name,
                        "old": str(c.old_value),
                        "new": str(c.new_value),
                        "type": c.change_type
                    }
                    for c in section_changes
                ]

                prompt = self._get_batch_reasoning_prompt(section_type, batch_data)
                
                response = await self.client.generate_content(
                    contents=prompt,
                    generation_config={"response_mime_type": "application/json"}
                )

                reasoning_results = parse_json_safely(response)
                if isinstance(reasoning_results, list):
                    for item in reasoning_results:
                        change_id = item.get("id")
                        reasonText = item.get("reason")
                        if change_id in enriched_changes:
                            enriched_changes[change_id].reasoning = reasonText

            except Exception as e:
                LOGGER.error(f"Failed to generate reasoning for section {section_type}: {e}", exc_info=True)

        return list(enriched_changes.values())

    async def generate_overall_explanation(self, changes: List[ComparisonChange]) -> str:
        """Generates a high-level summary of all material changes."""
        material_changes = [c for c in changes if c.change_type != "no_change" and c.severity in ["medium", "high"]]
        
        if not material_changes:
            return "No significant material changes were detected between the policies."

        # Summary of changes for LLM context
        summary_data = []
        for c in material_changes:
            summary_data.append(f"- {c.section_type}: {c.field_name} changed from {c.old_value} to {c.new_value} ({c.change_type})")

        prompt = (
            "You are an insurance policy expert. Compare the following material changes between an expiring policy and a renewal policy. "
            "Provide a concise, professional summary of the key differences that a broker or policyholder should be aware of. "
            "Focus on coverage gaps, limit changes, and premium impacts.\n\n"
            "Changes:\n" + "\n".join(summary_data[:50]) + "\n\n"
            "Provide the summary in plain text, maximum 3-4 sentences."
        )

        try:
            response = await self.client.generate_content(contents=prompt)
            return response.strip()
        except Exception as e:
            LOGGER.error(f"Failed to generate overall explanation: {e}", exc_info=True)
            return "Summary generation failed."

    def _get_batch_reasoning_prompt(self, section_type: str, batch_data: List[Dict]) -> str:
        return f"""You are an insurance technical auditor. Compare the following field-level changes in the '{section_type}' section of two insurance policies.
For each item, provide a very short, natural language explanation (one sentence max) of what the difference means.
Example for Coverages: "The occurrence limit increased from $1M to $2M, providing higher protection per claim."
Example for Exclusions: "A new exclusion for cyber-related losses was added, narrowing the scope of coverage."

Input Data (JSON):
{json.dumps(batch_data)}

Return a JSON list of objects with "id" and "reason" fields.
Example Output:
[
  {{"id": 12345, "reason": "The premium increased by 5%, reflecting updated risk assessment."}}
]
"""
