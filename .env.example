# Example .env configuration for LLM providers

# LLM Provider Configuration
# Choose between "gemini" or "openrouter"
LLM_PROVIDER=gemini

# Gemini Configuration (required if LLM_PROVIDER=gemini)
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.0-flash

# OpenRouter Configuration (required if LLM_PROVIDER=openrouter)
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_API_URL=https://openrouter.ai/api/v1/chat/completions
OPENROUTER_MODEL=openai/gpt-oss-20b:free

# LLM Fallback Configuration
# Enable automatic fallback to Gemini if OpenRouter fails
ENABLE_LLM_FALLBACK=false

DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/insura_ai

# Supabase Authentication Configuration
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your_supabase_anon_key_here
SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key_here
SUPABASE_JWKS_CACHE_TTL=3600
