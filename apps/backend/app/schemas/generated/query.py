# generated by datamodel-codegen:
#   filename:  query.json
#   timestamp: 2026-02-13T07:59:31+00:00

from __future__ import annotations

from datetime import datetime
from enum import Enum
from typing import Any
from uuid import UUID

from pydantic import BaseModel, Field, conint, constr


class Role(Enum):
    user = 'user'
    model = 'model'


class WorkflowMessage(BaseModel):
    id: UUID
    role: Role
    content: str
    additional_metadata: dict[str, Any] | None = None
    created_at: datetime


class MentionedDocument(BaseModel):
    id: UUID
    name: str
    signed_url: str | None = None


class IntentOverride(Enum):
    QA = 'QA'
    ANALYSIS = 'ANALYSIS'
    AUDIT = 'AUDIT'


class GraphRAGRequest(BaseModel):
    query: constr(min_length=1) = Field(..., description="User's natural language question")
    mentioned_documents: list[MentionedDocument] | None = Field(
        None, description='Documents explicitly mentioned via @ in the chat'
    )
    document_ids: list[UUID] | None = Field(
        None, description='Specific documents to query (None = all workflow docs)'
    )
    include_sources: bool | None = True
    max_context_tokens: conint(ge=1000, le=32000) | None = 8000
    intent_override: IntentOverride | None = None


class ResponseMetadata(BaseModel):
    intent: str
    traversal_depth: int
    vector_results_count: int
    graph_results_count: int
    merged_results_count: int
    full_text_count: int
    summary_count: int
    total_context_tokens: int
    latency_ms: int
    stage_latencies: dict[str, int] | None = None
    graph_available: bool | None = True
    fallback_mode: bool | None = False


class GraphRAGResponse(BaseModel):
    answer: str
    metadata: ResponseMetadata
    timestamp: datetime
